{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import os, json, re, sys\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from tokenize_tag import tokenize\n",
    "import parmap\n",
    "import pickle\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentence(sent):\n",
    "    sent = sent.strip()\n",
    "    sent = re.sub('{laughing}|{clearing}|{singing}|{applauding}', '', sent)\n",
    "    sent = re.sub('[(][(].*?[)][)]|-.*?-', '', sent)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_main_topic = lambda x: x.split(' > ')[0]\n",
    "\n",
    "def load_data():\n",
    "    file_list = [f_name for f_name in os.listdir('data') if f_name[-5:] == '.json']\n",
    "    \n",
    "    total_data = []\n",
    "    for f_name in tqdm(file_list):\n",
    "        with open('data/%s' %f_name, 'r') as f:\n",
    "            data = json.loads(f.read())['document'][0]\n",
    "            metadata = data['metadata']\n",
    "            utterance = data['utterance']\n",
    "            \n",
    "            topic = get_main_topic(metadata['topic'])\n",
    "            if topic[:4] == 'NWRW':\n",
    "                continue\n",
    "\n",
    "            last_speaker = None\n",
    "            seg1 = seg2 = ''\n",
    "            for u in utterance:\n",
    "                if last_speaker is None:\n",
    "                    last_speaker = u['speaker_id']\n",
    "                    seg2 = u['form']\n",
    "                elif last_speaker == u['speaker_id']:\n",
    "                    seg2 += ' ' + u['original_form']\n",
    "                else:\n",
    "                    if seg1 and seg2:\n",
    "                        total_data.append([f_name, topic, clean_sentence(seg1), clean_sentence(seg2)])\n",
    "                    last_speaker = u['speaker_id']\n",
    "                    seg1 = seg2\n",
    "                    seg2 = u['original_form']\n",
    "            if seg1 and seg2:\n",
    "                total_data.append([f_name, topic, clean_sentence(seg1), clean_sentence(seg2)])\n",
    "                \n",
    "    return np.array(total_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_to_list(row):\n",
    "    return str(row[2]), str(row[3]), label_w2i[row[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = load_data()\n",
    "file_with_label = np.unique(raw_dataset[:, :2], axis=0)\n",
    "_labels, _counts = np.unique(file_with_label[:, 1], return_counts=True)\n",
    "label_counts = dict(zip(_labels, _counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "np.random.shuffle(file_with_label)\n",
    "\n",
    "valid_list = {label: [] for label in label_counts}\n",
    "test_list = {label: [] for label in label_counts}\n",
    "\n",
    "for file in file_with_label:\n",
    "    if len(valid_list[file[1]]) < label_counts[file[1]] * 0.1:\n",
    "        valid_list[file[1]].append(file[0])\n",
    "    elif len(test_list[file[1]]) < label_counts[file[1]] * 0.1:\n",
    "        test_list[file[1]].append(file[0])\n",
    "        \n",
    "_valid_list = []\n",
    "_test_list = []\n",
    "for label in label_counts:\n",
    "    _valid_list.extend(valid_list[label])\n",
    "    _test_list.extend(test_list[label])\n",
    "    \n",
    "valid_list = _valid_list\n",
    "test_list = _test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_dataset, raw_valid_dataset, raw_test_dataset = [], [], []\n",
    "for row in raw_dataset:\n",
    "    if row[0] in valid_list:\n",
    "        raw_valid_dataset.append(row)\n",
    "    elif row[0] in test_list:\n",
    "        raw_test_dataset.append(row)\n",
    "    else:\n",
    "        raw_train_dataset.append(row)\n",
    "raw_train_dataset, raw_valid_dataset, raw_test_dataset = np.array(raw_train_dataset), np.array(raw_valid_dataset), np.array(raw_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "npz_file = np.load('raw_train_valid_test.npz')\n",
    "raw_train_dataset, raw_valid_dataset, raw_test_dataset = npz_file['arr_0'], npz_file['arr_1'], npz_file['arr_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_i2w = np.unique(raw_train_dataset[:, 1]).tolist()\n",
    "label_w2i = {w: i for i, w in enumerate(label_i2w)}\n",
    "label_i2w = {i: w for i, w in enumerate(label_i2w)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_w2i = pickle.load(open('ver_2.w2i', 'rb'))\n",
    "label_i2w = {label_w2i[l]: l for l in label_w2i}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = [str(r[2]) + ' ' + str(r[3]) for r in raw_train_dataset], np.array([label_w2i[r[1]] for r in raw_train_dataset])\n",
    "valid_x, valid_y = [str(r[2]) + ' ' + str(r[3]) for r in raw_valid_dataset], np.array([label_w2i[r[1]] for r in raw_valid_dataset])\n",
    "test_x, test_y = [str(r[2]) + ' ' + str(r[3]) for r in raw_test_dataset], np.array([label_w2i[r[1]] for r in raw_test_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:32<00:00,  1.62s/it]\n",
      "100%|██████████| 18629/18629 [01:23<00:00, 222.00it/s]\n",
      "100%|██████████| 20/20 [00:19<00:00,  1.02it/s]\n",
      "100%|██████████| 20/20 [00:16<00:00,  1.25it/s]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    total_size = len(train_x)\n",
    "    data = [train_x[int(total_size/os.cpu_count()*i):int(total_size/os.cpu_count()*(i+1))] for i in range(os.cpu_count())]\n",
    "    token_list = parmap.map(tokenize, data, pm_pbar=True, pm_processes=os.cpu_count())\n",
    "    \n",
    "    tokens = []\n",
    "    for t in token_list:\n",
    "        tokens.extend(t)\n",
    "        \n",
    "    i2w = []\n",
    "    for s in tqdm(tokens):\n",
    "        for t in s:\n",
    "            if t not in i2w:\n",
    "                i2w.append(t)\n",
    "    i2w = list(set(i2w))\n",
    "    i2w.insert(0, '[UNK]')\n",
    "    seq_len = len(i2w)\n",
    "    w2i = {t: i for i, t in enumerate(i2w)}\n",
    "    \n",
    "    train_x = np.zeros(shape=(len(tokens), seq_len))\n",
    "    for i, s in enumerate(tokens):\n",
    "        for t in s:\n",
    "            train_x[i][w2i[t]] += 1\n",
    "            \n",
    "            \n",
    "    total_size = len(valid_x)\n",
    "    data = [valid_x[int(total_size/os.cpu_count()*i):int(total_size/os.cpu_count()*(i+1))] for i in range(os.cpu_count())]\n",
    "    token_list = parmap.map(tokenize, data, pm_pbar=True, pm_processes=os.cpu_count())\n",
    "    \n",
    "    tokens = []\n",
    "    for t in token_list:\n",
    "        tokens.extend(t)\n",
    "        \n",
    "    valid_x = np.zeros(shape=(len(tokens), seq_len))\n",
    "    for i, s in enumerate(tokens):\n",
    "        for t in s:\n",
    "            valid_x[i][w2i[t] if t in w2i else 0] += 1\n",
    "            \n",
    "            \n",
    "    total_size = len(test_x)\n",
    "    data = [test_x[int(total_size/os.cpu_count()*i):int(total_size/os.cpu_count()*(i+1))] for i in range(os.cpu_count())]\n",
    "    token_list = parmap.map(tokenize, data, pm_pbar=True, pm_processes=os.cpu_count())\n",
    "    \n",
    "    tokens = []\n",
    "    for t in token_list:\n",
    "        tokens.extend(t)\n",
    "        \n",
    "    test_x = np.zeros(shape=(len(tokens), seq_len))\n",
    "    for i, s in enumerate(tokens):\n",
    "        for t in s:\n",
    "            test_x[i][w2i[t] if t in w2i else 0] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('bow_data.npz', train_x, train_y, valid_x, valid_y, test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump((i2w, w2i), open('bow_dict.pkl', 'wb'))\n",
    "pickle.dump((label_i2w, label_w2i), open('bow_label.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "i2w, w2i = pickle.load(open('bow_dict.pkl', 'rb'))\n",
    "label_i2w, label_w2i = pickle.load(open('bow_label.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_data = np.load('bow_data.npz')\n",
    "train_x, train_y, valid_x, valid_y, test_x, test_y = bow_data['arr_0'], bow_data['arr_1'], bow_data['arr_2'], bow_data['arr_3'], bow_data['arr_4'], bow_data['arr_5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['100.0000', '100.0000', '0.7785', '0.7948', '0.7797', '0.7742']\n",
      "['100.0000', '125.0000', '0.7846', '0.7984', '0.7880', '0.7823']\n",
      "['100.0000', '150.0000', '0.7862', '0.8033', '0.7894', '0.7853']\n",
      "['100.0000', '175.0000', '0.7862', '0.8027', '0.7889', '0.7839']\n",
      "['100.0000', '200.0000', '0.7834', '0.8005', '0.7868', '0.7819']\n",
      "100%|██████████| 5/5 [01:12<00:00, 14.55s/it]\n",
      "['125.0000', '100.0000', '0.7797', '0.7967', '0.7811', '0.7751']\n",
      "['125.0000', '125.0000', '0.7850', '0.8023', '0.7901', '0.7846']\n",
      "['125.0000', '150.0000', '0.7797', '0.8033', '0.7845', '0.7807']\n",
      "['125.0000', '175.0000', '0.7870', '0.8038', '0.7883', '0.7840']\n",
      "['125.0000', '200.0000', '0.7878', '0.8066', '0.7900', '0.7856']\n",
      "100%|██████████| 5/5 [01:29<00:00, 17.81s/it]\n",
      "['150.0000', '100.0000', '0.7858', '0.8034', '0.7883', '0.7825']\n",
      "['150.0000', '125.0000', '0.7891', '0.8058', '0.7927', '0.7870']\n",
      "['150.0000', '150.0000', '0.7834', '0.8047', '0.7867', '0.7826']\n",
      "['150.0000', '175.0000', '0.7874', '0.8050', '0.7894', '0.7846']\n",
      "['150.0000', '200.0000', '0.7899', '0.8065', '0.7930', '0.7875']\n",
      "100%|██████████| 5/5 [01:46<00:00, 21.24s/it]\n",
      "['175.0000', '100.0000', '0.7838', '0.7996', '0.7870', '0.7803']\n",
      "['175.0000', '125.0000', '0.7903', '0.8074', '0.7950', '0.7892']\n",
      "['175.0000', '150.0000', '0.7854', '0.8056', '0.7868', '0.7834']\n",
      "['175.0000', '175.0000', '0.7874', '0.8073', '0.7906', '0.7863']\n",
      "['175.0000', '200.0000', '0.7899', '0.8094', '0.7921', '0.7884']\n",
      "100%|██████████| 5/5 [02:04<00:00, 24.88s/it]\n",
      "['200.0000', '100.0000', '0.7870', '0.8036', '0.7895', '0.7835']\n",
      "['200.0000', '125.0000', '0.7878', '0.8056', '0.7921', '0.7865']\n",
      "['200.0000', '150.0000', '0.7866', '0.8077', '0.7897', '0.7866']\n",
      "['200.0000', '175.0000', '0.7948', '0.8124', '0.7975', '0.7934']\n",
      "['200.0000', '200.0000', '0.7960', '0.8127', '0.7979', '0.7942']\n",
      "100%|██████████| 5/5 [02:29<00:00, 29.82s/it]\n",
      "['225.0000', '100.0000', '0.7862', '0.8035', '0.7889', '0.7835']\n",
      "['225.0000', '125.0000', '0.7911', '0.8095', '0.7949', '0.7890']\n",
      "['225.0000', '150.0000', '0.7862', '0.8087', '0.7900', '0.7866']\n",
      "['225.0000', '175.0000', '0.7948', '0.8120', '0.7966', '0.7932']\n",
      "['225.0000', '200.0000', '0.7976', '0.8144', '0.7993', '0.7958']\n",
      "100%|██████████| 5/5 [02:47<00:00, 33.41s/it]\n",
      "['250.0000', '100.0000', '0.7882', '0.8050', '0.7899', '0.7849']\n",
      "['250.0000', '125.0000', '0.7899', '0.8088', '0.7940', '0.7889']\n",
      "['250.0000', '150.0000', '0.7874', '0.8100', '0.7900', '0.7869']\n",
      "['250.0000', '175.0000', '0.7940', '0.8097', '0.7944', '0.7907']\n",
      "['250.0000', '200.0000', '0.7936', '0.8099', '0.7952', '0.7908']\n",
      "100%|██████████| 5/5 [02:54<00:00, 34.97s/it]\n",
      "['275.0000', '100.0000', '0.7870', '0.8043', '0.7886', '0.7835']\n",
      " 20%|██        | 1/5 [00:42<02:48, 42.25s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-15b19a84a293>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m123456\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         )\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mvalid_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         result.append((\n",
      "\u001b[0;32m~/Dialog-Classification-Using-KoBERT/venv_kcc/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    391\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                     n_samples_bootstrap=n_samples_bootstrap)\n\u001b[0;32m--> 393\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dialog-Classification-Using-KoBERT/venv_kcc/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dialog-Classification-Using-KoBERT/venv_kcc/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_estimators = [100, 125, 150, 175, \n",
    "                200, 225, 250, 275, 300]\n",
    "max_depth = [100, 125, 150, 175, 200]\n",
    "result = []\n",
    "for n in n_estimators:\n",
    "    for d in tqdm(max_depth, file=sys.stdout):\n",
    "        rf = RandomForestClassifier(\n",
    "            n_estimators=n, max_depth=d,\n",
    "            random_state=123456, n_jobs=-1\n",
    "        )\n",
    "        rf.fit(train_x, train_y)\n",
    "        valid_pred = rf.predict(valid_x)\n",
    "        result.append((\n",
    "            n, d,\n",
    "            (valid_pred == valid_y).sum() / len(valid_y), \n",
    "            precision_score(valid_y, valid_pred, average='macro'), \n",
    "            recall_score(valid_y, valid_pred, average='macro'), \n",
    "            f1_score(valid_y, valid_pred, average='macro')\n",
    "        ))\n",
    "        tqdm.write(str(['%.04f' %r for r in result[-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=200, n_estimators=225, n_jobs=-1,\n",
       "                       random_state=123456)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(\n",
    "    n_estimators=225, max_depth=200,\n",
    "    random_state=123456, n_jobs=-1\n",
    ")\n",
    "rf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(rf, open('rf.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Label | Precision | Recall | F1 |\n",
      "|-------|-----------|--------|----|\n",
      "| 가족 | 0.9464 | 0.5000 | 0.6543 |\n",
      "| 건강/다이어트 | 0.7949 | 0.8455 | 0.8194 |\n",
      "| 계절/날씨 | 0.8054 | 0.9023 | 0.8511 |\n",
      "| 꿈(목표) | 0.7647 | 0.6915 | 0.7263 |\n",
      "| 먹거리 | 0.9049 | 0.9189 | 0.9119 |\n",
      "| 반려동물 | 0.9015 | 1.0000 | 0.9482 |\n",
      "| 방송/연예 | 0.8882 | 0.5479 | 0.6777 |\n",
      "| 선물 | 0.9906 | 0.8898 | 0.9375 |\n",
      "| 성격 | 0.9483 | 0.8800 | 0.9129 |\n",
      "| 스포츠/레저 | 0.9504 | 0.7012 | 0.8070 |\n",
      "| 아르바이트 | 0.7808 | 0.9828 | 0.8702 |\n",
      "| 여행지(국내/해외) | 0.7477 | 0.9639 | 0.8421 |\n",
      "| 연애/결혼 | 0.8061 | 0.9568 | 0.8750 |\n",
      "| 영화 | 0.6473 | 0.9944 | 0.7841 |\n",
      "| 회사/학교 | 0.7602 | 0.6915 | 0.7242 |\n",
      "| Total | 0.8425 | 0.8311 | 0.8228 |\n",
      "Test Accuracy : 0.8239\n"
     ]
    }
   ],
   "source": [
    "test_pred = rf.predict(test_x)\n",
    "test_true = test_y\n",
    "\n",
    "test_acc = (test_pred == test_true).sum() / len(test_true)\n",
    "test_precision = [precision_score(test_true, test_pred, labels=[i], average='macro') for i in label_i2w]\n",
    "test_recall = [recall_score(test_true, test_pred, labels=[i], average='macro') for i in label_i2w]\n",
    "test_f1 = [f1_score(test_true, test_pred, labels=[i], average='macro') for i in label_i2w]\n",
    "\n",
    "print('| Label | Precision | Recall | F1 |')\n",
    "print('|-------|-----------|--------|----|')\n",
    "for i, (precision, recall, f1) in enumerate(zip(test_precision, test_recall, test_f1)):\n",
    "    print('| %s | %.4f | %.4f | %.4f |' %(label_i2w[i], precision, recall, f1))\n",
    "print('| %s | %.4f | %.4f | %.4f |' %(\n",
    "    'Total', \n",
    "    precision_score(test_true, test_pred, average='macro'), \n",
    "    recall_score(test_true, test_pred, average='macro'), \n",
    "    f1_score(test_true, test_pred, average='macro'), \n",
    "))\n",
    "\n",
    "print('Test Accuracy : %.4f' %test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s][03:03:45] WARNING: /home/svclaw2000/xgboost/python-package/build/temp.linux-x86_64-3.7/xgboost/src/learner.cc:572: \n",
      "Parameters: { \"mthread\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[03:03:57] WARNING: /home/svclaw2000/xgboost/python-package/build/temp.linux-x86_64-3.7/xgboost/src/learner.cc:1094: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "['4.0000', '0.8762', '0.8135', '0.8197', '0.8125']\n",
      " 25%|██▌       | 1/4 [15:41<47:04, 941.67s/it][03:19:27] WARNING: /home/svclaw2000/xgboost/python-package/build/temp.linux-x86_64-3.7/xgboost/src/learner.cc:572: \n",
      "Parameters: { \"mthread\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[03:19:44] WARNING: /home/svclaw2000/xgboost/python-package/build/temp.linux-x86_64-3.7/xgboost/src/learner.cc:1094: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "['6.0000', '0.8713', '0.8125', '0.8188', '0.8114']\n",
      " 50%|█████     | 2/4 [39:26<40:52, 1226.00s/it][03:43:12] WARNING: /home/svclaw2000/xgboost/python-package/build/temp.linux-x86_64-3.7/xgboost/src/learner.cc:572: \n",
      "Parameters: { \"mthread\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[03:43:33] WARNING: /home/svclaw2000/xgboost/python-package/build/temp.linux-x86_64-3.7/xgboost/src/learner.cc:1094: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "['8.0000', '0.8682', '0.8078', '0.8146', '0.8069']\n",
      " 75%|███████▌  | 3/4 [1:19:14<29:16, 1756.57s/it][04:23:00] WARNING: /home/svclaw2000/xgboost/python-package/build/temp.linux-x86_64-3.7/xgboost/src/learner.cc:572: \n",
      "Parameters: { \"mthread\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[04:23:36] WARNING: /home/svclaw2000/xgboost/python-package/build/temp.linux-x86_64-3.7/xgboost/src/learner.cc:1094: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "['10.0000', '0.8682', '0.8049', '0.8168', '0.8072']\n",
      "100%|██████████| 4/4 [2:09:39<00:00, 1944.85s/it]\n"
     ]
    }
   ],
   "source": [
    "max_depth = [4, 6, 8, 10]\n",
    "result = []\n",
    "# for n in n_estimators:\n",
    "for d in tqdm(max_depth, file=sys.stdout):\n",
    "    xgb = XGBClassifier(\n",
    "        objective='multi:softprob', \n",
    "        max_depth=d,\n",
    "        seed=123456,\n",
    "        random_state=123456,\n",
    "        mthread=os.cpu_count(),\n",
    "        use_label_encoder=False\n",
    "    )\n",
    "    xgb.fit(train_x, train_y)\n",
    "    valid_pred = xgb.predict(valid_x)\n",
    "    result.append((\n",
    "        d,\n",
    "        (valid_pred == valid_y).sum() / len(test_true), \n",
    "        precision_score(valid_y, valid_pred, average='macro'), \n",
    "        recall_score(valid_y, valid_pred, average='macro'), \n",
    "        f1_score(valid_y, valid_pred, average='macro')\n",
    "    ))\n",
    "    tqdm.write(str(['%.04f' %r for r in result[-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:27:49] WARNING: /home/svclaw2000/xgboost/python-package/build/temp.linux-x86_64-3.7/xgboost/src/learner.cc:572: \n",
      "Parameters: { \"mthread\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13:28:01] WARNING: /home/svclaw2000/xgboost/python-package/build/temp.linux-x86_64-3.7/xgboost/src/learner.cc:1094: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=4,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              mthread=20, n_estimators=100, n_jobs=20, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=123456, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, seed=123456, subsample=1,\n",
       "              tree_method='exact', use_label_encoder=False,\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier(\n",
    "    objective='multi:softprob', \n",
    "    max_depth=4,\n",
    "    seed=123456,\n",
    "    random_state=123456,\n",
    "    mthread=os.cpu_count(),\n",
    "    use_label_encoder=False\n",
    ")\n",
    "xgb.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(xgb, open('xgb.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Label | Precision | Recall | F1 |\n",
      "|-------|-----------|--------|----|\n",
      "| 가족 | 0.7778 | 0.5943 | 0.6738 |\n",
      "| 건강/다이어트 | 0.7521 | 0.8273 | 0.7879 |\n",
      "| 계절/날씨 | 0.9008 | 0.8872 | 0.8939 |\n",
      "| 꿈(목표) | 0.6500 | 0.6915 | 0.6701 |\n",
      "| 먹거리 | 0.9206 | 0.8958 | 0.9080 |\n",
      "| 반려동물 | 0.8947 | 1.0000 | 0.9444 |\n",
      "| 방송/연예 | 0.8876 | 0.5747 | 0.6977 |\n",
      "| 선물 | 0.9633 | 0.8898 | 0.9251 |\n",
      "| 성격 | 0.9310 | 0.8640 | 0.8963 |\n",
      "| 스포츠/레저 | 0.8824 | 0.8232 | 0.8517 |\n",
      "| 아르바이트 | 0.8467 | 1.0000 | 0.9170 |\n",
      "| 여행지(국내/해외) | 0.7407 | 0.9639 | 0.8377 |\n",
      "| 연애/결혼 | 0.7661 | 0.9424 | 0.8452 |\n",
      "| 영화 | 0.7860 | 0.9441 | 0.8579 |\n",
      "| 회사/학교 | 0.7688 | 0.7074 | 0.7368 |\n",
      "| Total | 0.8312 | 0.8404 | 0.8296 |\n",
      "Test Accuracy : 0.8322\n"
     ]
    }
   ],
   "source": [
    "test_pred = xgb.predict(test_x)\n",
    "test_true = test_y\n",
    "\n",
    "test_acc = (test_pred == test_true).sum() / len(test_true)\n",
    "test_precision = [precision_score(test_true, test_pred, labels=[i], average='macro') for i in label_i2w]\n",
    "test_recall = [recall_score(test_true, test_pred, labels=[i], average='macro') for i in label_i2w]\n",
    "test_f1 = [f1_score(test_true, test_pred, labels=[i], average='macro') for i in label_i2w]\n",
    "\n",
    "print('| Label | Precision | Recall | F1 |')\n",
    "print('|-------|-----------|--------|----|')\n",
    "for i, (precision, recall, f1) in enumerate(zip(test_precision, test_recall, test_f1)):\n",
    "    print('| %s | %.4f | %.4f | %.4f |' %(label_i2w[i], precision, recall, f1))\n",
    "print('| %s | %.4f | %.4f | %.4f |' %(\n",
    "    'Total', \n",
    "    precision_score(test_true, test_pred, average='macro'), \n",
    "    recall_score(test_true, test_pred, average='macro'), \n",
    "    f1_score(test_true, test_pred, average='macro'), \n",
    "))\n",
    "\n",
    "print('Test Accuracy : %.4f' %test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18629/18629 [00:28<00:00, 664.95it/s]\n"
     ]
    }
   ],
   "source": [
    "length_count = [[0, 0] for _ in label_i2w]\n",
    "\n",
    "for i in tqdm(range(len(train_x))):\n",
    "    length_count[train_y[i]][0] += sum(train_x[i])\n",
    "    length_count[train_y[i]][1] += 1\n",
    "    \n",
    "for i in range(len(valid_x)):\n",
    "    length_count[valid_y[i]][0] += sum(valid_x[i])\n",
    "    length_count[valid_y[i]][1] += 1\n",
    "    \n",
    "for i in range(len(test_x)):\n",
    "    length_count[test_y[i]][0] += sum(test_x[i])\n",
    "    length_count[test_y[i]][1] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "552.0\t가족\n",
      "478.0\t건강/다이어트\n",
      "339.0\t계절/날씨\n",
      "527.0\t꿈(목표)\n",
      "334.0\t먹거리\n",
      "479.0\t반려동물\n",
      "330.0\t방송/연예\n",
      "481.0\t선물\n",
      "468.0\t성격\n",
      "398.0\t스포츠/레저\n",
      "471.0\t아르바이트\n",
      "336.0\t여행지(국내/해외)\n",
      "467.0\t연애/결혼\n",
      "336.0\t영화\n",
      "362.0\t회사/학교\n"
     ]
    }
   ],
   "source": [
    "for i, (l, c) in enumerate(length_count):\n",
    "#     print('%.3f' %(l//c), label_i2w[i], sep='\\t')\n",
    "    print(l//c, label_i2w[i], sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KCC",
   "language": "python",
   "name": "venv_kcc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
